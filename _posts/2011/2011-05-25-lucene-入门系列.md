---
layout: post
title: Lucene 入门系列（一）
category: java
tags: [java,lucene]
---

# LUCENE 入门系列 #

## 简介 ##

Lucene Core, our flagship sub-project, provides Java-based indexing and search technology, as well as spellchecking, hit highlighting and advanced analysis/tokenization capabilities.

## RAMDirectory中的内容转到FSDirectory ##
``` javav 
import java.io.IOException;  
  
import org.apache.lucene.analysis.standard.StandardAnalyzer;  
import org.apache.lucene.document.Document;  
import org.apache.lucene.document.Field;  
import org.apache.lucene.document.Field.Index;  
import org.apache.lucene.document.Field.Store;  
import org.apache.lucene.index.CorruptIndexException;  
import org.apache.lucene.index.IndexWriter;  
import org.apache.lucene.index.Term;  
import org.apache.lucene.search.Hits;  
import org.apache.lucene.search.IndexSearcher;  
import org.apache.lucene.search.TermQuery;  
import org.apache.lucene.store.Directory;  
import org.apache.lucene.store.FSDirectory;  
import org.apache.lucene.store.LockObtainFailedException;  
import org.apache.lucene.store.RAMDirectory;  
  
/** 
 * @author Vincnet 
 * @version 2.3 
 *  
 */  
public class Test {  
    public static void main(String[] args) throws CorruptIndexException,  
            LockObtainFailedException, IOException {  
        long data1 = System.currentTimeMillis();  
          
        /** 
         * 分别创建两个对象 
         * */  
        FSDirectory fsDir = FSDirectory.getDirectory("E:\\Lucene\\Index2\\");  
        RAMDirectory ramDir = new RAMDirectory();  
          
        IndexWriter ramwriter = new IndexWriter(ramDir, new StandardAnalyzer(),true);  
        IndexWriter fsdwriter = new IndexWriter(fsDir, new StandardAnalyzer(),true);  
          
        Document document = new Document();  
        /** 
         * Field(String name, String value, Field.Store store, Field.Index index) 
         * Create a field by specifying its name, value and how it will be saved in the index. 
         * 
         */  
        document.add(new Field("name","Vincnet",Store.YES,Index.TOKENIZED));  
        document.add(new Field("age","18",Store.YES,Index.UN_TOKENIZED));  
        document.add(new Field("note","this is a test data",Store.YES,Index.TOKENIZED));  
        ramwriter.addDocument(document);  
        fsdwriter.addDocument(document);  
        ramwriter.flush();  
          
        //将fsd里面的索引和ram的索引合并成同一个所以 关键一句   
        fsdwriter.addIndexes(new Directory[]{ramDir});  
        ramwriter.close();  
        fsdwriter.flush();  
        fsdwriter.close();  
          
        IndexSearcher searcher = new IndexSearcher(ramDir);  
          
        Hits hits = searcher.search(new TermQuery(new Term("name","vincnet")));  
        for(int i = 0 ; i < hits.length() ; i++){  
            System.out.println(hits.length()+"   "+hits.doc(i).get("name"));  
        }  
        searcher.close();  
          
        System.out.println("运行时间 ： "+(System.currentTimeMillis() - data1)+" ms");  
    }  
}  
``` 
## lucene-建立索引的入门例子 ##
``` java
package org.sam.demo.lucene;  
  
import java.io.IOException;  
import java.sql.SQLException;  
import java.util.List;  
  
import org.apache.lucene.analysis.standard.StandardAnalyzer;  
import org.apache.lucene.document.Document;  
import org.apache.lucene.document.Field;  
import org.apache.lucene.index.CorruptIndexException;  
import org.apache.lucene.index.IndexWriter;  
import org.apache.lucene.store.LockObtainFailedException;  
import org.sam.demo.mysql.Authors;  
import org.sam.demo.mysql.DBOperation;  
  
/** 
 * @author Sam 
 * @copyright_code 123456789987654321 
 * @Date 2008-09-16 
 * */  
public class IndexCreate {  
    /* 索引存放的路径，如果找不到会有IOException */  
    private final String PATH="E:/Lucene/Index6";  
    public static void main(String[] args) throws CorruptIndexException,   
            LockObtainFailedException, IOException, SQLException, ClassNotFoundException {  
        IndexCreate one = new IndexCreate();  
//      one.createIndexOne(new DBOperation().getAuthors("000e5f51-f671-47f0-a6bd-0c46a969f162"));  
        one.createIndexList(new DBOperation().getAuthorses());  
    }  
      
    /** 
     * 建立一个对象的索引 
     * @throws IOException  
     * @throws LockObtainFailedException  
     * @throws CorruptIndexException  
     * */  
    public void createIndexOne(Authors s) throws CorruptIndexException,  
            LockObtainFailedException, IOException{  
        /* Field(String name, String value, Field.Store store, Field.Index index) 个人习惯选择这个构造方法 */  
        Field f1 = new Field("id",s.getAu_id(),Field.Store.YES,Field.Index.UN_TOKENIZED);  
        Field f2 = new Field("lname",s.getAu_lname(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f3 = new Field("fname",s.getAu_fname(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f4 = new Field("phone",s.getPhone(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f5 = new Field("address",s.getAddress(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f6 = new Field("city",s.getCity(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f7 = new Field("zip",s.getZip(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f8 = new Field("state",s.getState(),Field.Store.YES,Field.Index.TOKENIZED);  
        Field f9 = new Field("contract",s.getContract()+"",Field.Store.YES,Field.Index.TOKENIZED);  
        Document doc = new Document();  
        doc.add(f1);  
        doc.add(f2);  
        doc.add(f3);  
        doc.add(f4);  
        doc.add(f5);  
        doc.add(f6);  
        doc.add(f7);  
        doc.add(f8);  
        doc.add(f9);  
        IndexWriter writer = null;  
        try {  
            writer = new IndexWriter(PATH,new StandardAnalyzer(),true);  
            writer.addDocument(doc);  
        } finally{  
            writer.optimize();  
            writer.flush();  
            writer.close();  
        }  
    }  
      
    /** 
     * 建立一个List对象的索引 
     * @throws IOException  
     * @throws LockObtainFailedException  
     * @throws CorruptIndexException  
     * */  
    public void createIndexList(List<Authors> list) throws CorruptIndexException, LockObtainFailedException, IOException{  
        IndexWriter writer = null;  
        writer = new IndexWriter(PATH,new StandardAnalyzer(),true);  
        try {  
            for(Authors s : list){  
                Field f1 = new Field("id",s.getAu_id(),Field.Store.YES,Field.Index.UN_TOKENIZED);  
                Field f2 = new Field("lname",s.getAu_lname(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f3 = new Field("fname",s.getAu_fname(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f4 = new Field("phone",s.getPhone(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f5 = new Field("address",s.getAddress(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f6 = new Field("city",s.getCity(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f7 = new Field("zip",s.getZip(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f8 = new Field("state",s.getState(),Field.Store.YES,Field.Index.TOKENIZED);  
                Field f9 = new Field("contract",s.getContract()+"",Field.Store.YES,Field.Index.TOKENIZED);  
                Document doc = new Document();  
                doc.add(f1);  
                doc.add(f2);  
                doc.add(f3);  
                doc.add(f4);  
                doc.add(f5);  
                doc.add(f6);  
                doc.add(f7);  
                doc.add(f8);  
                doc.add(f9);  
                writer.addDocument(doc);  
            }  
        } finally{  
            writer.optimize();  
            writer.flush();  
            writer.close();  
        }  
    }  
}  
```
## lucene-搜索的入门例子 ##
``` java
package org.sam.demo.lucene;  
  
import java.io.IOException;  
  
import org.apache.lucene.analysis.standard.StandardAnalyzer;  
import org.apache.lucene.index.CorruptIndexException;  
import org.apache.lucene.queryParser.ParseException;  
import org.apache.lucene.queryParser.QueryParser;  
import org.apache.lucene.search.BooleanClause;  
import org.apache.lucene.search.BooleanQuery;  
import org.apache.lucene.search.Hits;  
import org.apache.lucene.search.IndexSearcher;  
import org.apache.lucene.search.Query;  
  
/** 
 * @author Sam 
 * @copyright_code 123456789987654321 
 * @Date 2008-09-16 
 * */  
public class Search {  
    private final String PATH="E:/Lucene/Index6/";  
    /* 关于搜索lucene提供了很多类，基本上需要用的也不多，所以这里我就写一些比较常用的！ */  
    public static void main(String[] args) throws CorruptIndexException, IOException, ParseException {  
//      new Search().termSearch("lname","Carson");  
          
        String[] keys = {"state","city"};  
        String[] values = {"CA","Oakland"};  
        new Search().booleanSerach(keys,values);  
    }  
      
    public void termSearch(String key,String value) throws CorruptIndexException, IOException, ParseException{  
        QueryParser qp = new QueryParser(key,new StandardAnalyzer());  
        IndexSearcher search = new IndexSearcher(PATH);  
        Query tq = qp.parse(value);  
        Hits hits = search.search(tq);  
        System.out.println(hits.length());  
        for(int i = 0 ; i < hits.length() ;i++){  
            System.out.println(hits.doc(i).get(key));  
        }  
        search.close();  
    }  
      
    public void booleanSerach(String[] keys,String[] values) throws CorruptIndexException, IOException, ParseException{  
        QueryParser qp = null;  
        BooleanQuery bq = null;  
        IndexSearcher search = new IndexSearcher(PATH);  
        for(int i = 0 ; i < keys.length ; i++){  
            qp = new QueryParser(keys[i],new StandardAnalyzer());  
            Query tq = qp.parse(values[i]);  
            bq = new BooleanQuery();  
            bq.add(tq, BooleanClause.Occur.MUST);  
        }  
        Hits hits = search.search(bq);  
        System.out.println(hits.length());  
        for(int i = 0 ; i < hits.length() ;i++){  
            for(int j = 0 ; j < keys.length ; j++)  
                System.out.print(hits.doc(i).get(keys[j])+"  ");  
            System.out.println();  
        }  
        search.close();  
    }  
}  
```
## lucene-过滤器的入门例子 ##
``` java
package org.sam.demo.lucene;  
  
import java.io.IOException;  
import java.util.BitSet;  
  
import org.apache.lucene.index.IndexReader;  
import org.apache.lucene.index.Term;  
import org.apache.lucene.index.TermDocs;  
import org.apache.lucene.search.Filter;  
/** 
 * @author Sam 
 * @copyright_code 123456789987654321 
 * @Date 2008-09-16 
 * */  
public class DynamicFilter extends Filter{  
    public String fieldValue = "";  
    public String fieldKey = "";  
      
      
      
    public DynamicFilter(String fieldKey,String security_advanced) {  
        super();  
        fieldValue = security_advanced;  
        this.fieldKey = fieldKey;  
    }  
  
  
  
    @Override  
    public BitSet bits(IndexReader reader) throws IOException {  
        /* 这个是过滤一个指定Term 返回其他 */  
        final BitSet bits = new BitSet(reader.maxDoc());  
        /* 设置一个 bits 的大小  */  
        bits.set(0,bits.size()-1);  
        Term term = new Term(fieldKey,fieldValue);  
        TermDocs termDocs = reader.termDocs(term);  
        while(termDocs.next()){  
            bits.set(termDocs.doc(),false);  
        }  
        return bits;  
          
          
        /* 这个是返回一个指定的 Term  */  
/*      BitSet result=new BitSet(reader.maxDoc()); 
        Term term = new Term(this.fieldKey,this.fieldValue); 
        TermDocs td=reader.termDocs(term); 
        while (td.next()) 
        { 
            result.set(td.doc()); 
        }                        
        return result; */  
    }  
  
}  
``` 
``` java 
package org.sam.demo.lucene;  
  
import java.io.IOException;  
  
import org.apache.lucene.analysis.standard.StandardAnalyzer;  
import org.apache.lucene.index.CorruptIndexException;  
import org.apache.lucene.index.Term;  
import org.apache.lucene.queryParser.ParseException;  
import org.apache.lucene.queryParser.QueryParser;  
import org.apache.lucene.search.BooleanClause;  
import org.apache.lucene.search.BooleanQuery;  
import org.apache.lucene.search.Hits;  
import org.apache.lucene.search.IndexSearcher;  
import org.apache.lucene.search.Query;  
import org.apache.lucene.search.TermsFilter;  
  
/** 
 * @author Sam 
 * @copyright_code 123456789987654321 
 * @Date 2008-09-16 
 * */  
public class AdvancedSearch {  
    private final String PATH="E:/Lucene/Index6/";  
    /* 关于搜索lucene提供了很多类，基本上需要用的也不多，所以这里我就写一些比较常用的！ */  
    public static void main(String[] args) throws CorruptIndexException, IOException, ParseException {  
        String[] keys = {"state","city"};  
        String[] values = {"CA","Oakland"};  
        new AdvancedSearch().booleanSerach(keys,values);  
    }  
      
    public void booleanSerach(String[] keys,String[] values) throws CorruptIndexException, IOException, ParseException{  
        QueryParser qp = null;  
        BooleanQuery bq = null;  
        IndexSearcher search = new IndexSearcher(PATH);  
        for(int i = 0 ; i < keys.length ; i++){  
            qp = new QueryParser(keys[i],new StandardAnalyzer());  
            Query tq = qp.parse(values[i]);  
            bq = new BooleanQuery();  
            bq.add(tq, BooleanClause.Occur.MUST);  
        }  
        Term t = new Term("fname","Dirk");  
        TermsFilter tf = new TermsFilter();  
        tf.addTerm(t);  
        Hits hits = search.search(bq,new DynamicFilter("fname","Dirk"));  
//      Hits hits = search.search(bq,tf);  
        System.out.println(hits.length());  
        for(int i = 0 ; i < hits.length() ;i++){  
            for(int j = 0 ; j < keys.length ; j++)  
                System.out.print(hits.doc(i).get(keys[j])+"  ");  
            System.out.println();  
        }  
        search.close();  
    }  
}  
```
## lucene--分词器的分析 ##
``` java
Java代码 
/** 
 * SimpleAnalyzer  这个分词是一段一段话进行分 
 * StandardAnalyzer 标准分词拿来分中文和ChineseAnalyzer一样的效果 
 ☆ PerFieldAnalyzerWrapper  这个很有意思，可以封装很多分词方式，还可以于先设置field用那个分词分！牛 
 * CJKAnalyzer  这个分词方式是正向退一分词(二分法分词)，同一个字会和它的左边和右边组合成一个次，每个人出现两次，除了首字和末字 
 * ChineseAnalyzer  这个是专业的中文分词器，一个一个字分 
 * BrazilianAnalyzer 巴西语言分词 
 * CzechAnalyzer 捷克语言分词 
 * DutchAnalyzer 荷兰语言分词 
 * FrenchAnalyzer 法国语言分词 
 * GermanAnalyzer 德国语言分词 
 * GreekAnalyzer 希腊语言分词 
 * RussianAnalyzer 俄罗斯语言分词 
 * ThaiAnalyzer 泰国语言分词 
 * KeywordAnalyzer "Tokenizes" the entire stream as a single token. This is useful for data like zip codes, ids, and some product names. 
 * PatternAnalyzer api讲这个分词方式很快，它是放在内存里面的 
 * SnowballAnalyzer 经典分词用具 主要支持欧洲语言 
 * StopAnalyzer 被忽略的词的分词器 
 * WhitespaceAnalyzer 空格分词 
 * */  
public class AnalyzerTest {  
    public static void main(String[] args) throws IOException {  
        String content = "中国人打阿斯顿看了附件阿斯利康的附件 就阿拉山口发动机";  
        StringReader reader = new StringReader(content);  
//      Analyzer analyzer = new org.apache.lucene.analysis.snowball.SnowballAnalyzer("English");  
        Analyzer analyzer = new StandardAnalyzer();  
        TokenStream ts = analyzer.tokenStream("", reader);  
        Token t = null;  
        while((t = ts.next()) != null){  
            System.out.println(t.termText()+"---"+new String(t.termBuffer(),0,t.termLength())+"----"+t.termLength());  
        }  
    }  
}  
``` 
在打印出来的数据就就是分词的结果，也就是说，打印出来的你都可以搜索得到，没打印出来的就搜索不到   

## lucene--同义词简单的实现方式 ##
``` java
public class CreateIndex2 {  
    private static final String PATH = "E:/Lucene/Index3/";  
    private static final String CONTENT = "NOKA";  
      
    public static void main(String[] args) throws CorruptIndexException,  
            LockObtainFailedException, IOException, ParseException {  
        CreateIndex2 index = new CreateIndex2();  
        index.createIndex();  
        index.search();  
    }  
      
    private void createIndex() throws CorruptIndexException, LockObtainFailedException, IOException{  
        IndexWriter writer = new IndexWriter(PATH,getAnalyzer(), true);  
        int i = 0;  
        while (i++ < 10) {  
            Document doc = new Document();  
            Document doc2 = new Document();  
  
            doc.add(new Field("content", "上海",  Field.Store.YES, Field.Index.TOKENIZED));  
            doc.add(new Field("content", "泸",   Field.Store.YES, Field.Index.TOKENIZED));  
              
            doc2.add(new Field("content", "诺基亚", Field.Store.YES,   Field.Index.TOKENIZED));  
            doc2.add(new Field("content", "NOKIA", Field.Store.YES, Field.Index.TOKENIZED));  
  
            writer.addDocument(doc);  
            writer.addDocument(doc2);  
  
        }  
        writer.optimize();  
        writer.close();  
    }  
      
    private void search() throws CorruptIndexException, IOException, ParseException{  
        IndexSearcher searcher = new IndexSearcher(PATH);  
        QueryParser parser = new QueryParser("content",getAnalyzer());  
        Query query = parser.parse(CONTENT);  
        Hits hits = searcher.search(query);  
        System.out.println(hits.length());  
        searcher.close();  
    }  
      
    private Analyzer getAnalyzer(){  
        return new StandardAnalyzer();  
    }  
}  
```
## lucene实时建立索引--注意事项 ##
  
实时建立索引一直是我思考的问题，虽然现在这个问题还没有圆满解决，但是我总结出了一些注意事项，现在先记录下来！

第一，确保IndexWriter只有一个，建议做一个静态的IndexWriter，只有一个路径去打开和关闭！

第二，确保只有一条线程去建立索引，因为lucene的索引文件带有自定义的锁文件，如果有多条线程去修改索引会出现异常！

第三，确保定时去优化索引文件，建议晚上2点到4点去优化，在优化的时候是不能建立索引的，但是2点到4点的访问量应该是较低的，所以应该是没有问题的。如果不优化索引，等到索引库很庞大之后优化的时间就会更长，需要的空间和内存更多。

第四，确保可以关闭IndexWriter，否则下次将无法打开索引文件，ps:虽然可以通过删除*.lock文件重新打开，但是不保证索引文件是否已经损坏了。

暂时只想到这么多，想到在更新补充！ 

## 实时建立索引的架构 ##

首先解释一下这个图的目的，当User通过http提交信息之后，假如该信息需要保存到数据库并且做索引，那么web服务器会将该对象保存到数据库，并且同时将这个对象发送给object-dispatcher 服务器，当object-dispacher服务器接收成功后为结束。web服务器将可以返回信息给用户，告诉用户保存成功。

object-dispatcher服务器是做为一个对象缓冲池，由于做索引的速度比较慢，在没有做索引之前我们需要将对象保存在object-dispacher服务器，index 服务器相会不停的向object-dispatcher服务器获取对象，直到清空object-dispatcher服务器里面缓存的对象。

当然，object-dispacher服务器有一个上线，当对象累计到一定量的时候，就会拒绝接收对象，当接收对象失败之后web服务器会记录下该对象没有做索引。

[工程下载](http://tg1a176.mail.163.com/app/wp/doGetFile.jsp?sid=WEtYEkTTlbNiYdUFyjTTfPhLhrFLMmzr&mode=download&mid=421:xtbBpQxZfU0vHMHOSgAAs2)